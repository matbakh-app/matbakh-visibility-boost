{"file":"/Users/matbakh-visibility-boost.20250920/src/lib/ai-orchestrator/bandit-optimizer.ts","mappings":";AAAA;;;;;;;;;GASG;;;AAEH,2DAK6B;AA2C7B,MAAa,eAAe;IAClB,MAAM,CAAiB;IACvB,iBAAiB,CAA8B;IAC/C,MAAM,CAAqB;IAC3B,mBAAmB,GAKtB,EAAE,CAAC;IAER,YACE,MAAuB,EACvB,iBAA8C,EAC9C,MAAoC;QAEpC,IAAI,CAAC,MAAM,GAAG,MAAM,IAAI,IAAI,kCAAc,EAAE,CAAC;QAC7C,IAAI,CAAC,iBAAiB,GAAG,iBAAiB,CAAC;QAC3C,IAAI,CAAC,MAAM,GAAG;YACZ,eAAe,EAAE,GAAG;YACpB,eAAe,EAAE,IAAI;YACrB,sBAAsB,EAAE,EAAE;YAC1B,uBAAuB,EAAE,IAAI;YAC7B,oBAAoB,EAAE,EAAE,EAAE,SAAS;YACnC,GAAG,MAAM;SACV,CAAC;QAEF,IAAI,IAAI,CAAC,MAAM,CAAC,uBAAuB,EAAE,CAAC;YACxC,IAAI,CAAC,qBAAqB,EAAE,CAAC;QAC/B,CAAC;IACH,CAAC;IAED;;OAEG;IACH,YAAY,CAAC,OAAuB;QAClC,MAAM,KAAK,GAAG,IAAI,CAAC,MAAM,CAAC,QAAQ,CAAC,OAAO,CAAC,CAAC;QAC5C,MAAM,WAAW,GAAG,MAAM,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC,MAAM,CAC7C,CAAC,GAAG,EAAE,IAAI,EAAE,EAAE,CAAC,GAAG,GAAG,IAAI,CAAC,MAAM,EAChC,CAAC,CACF,CAAC;QAEF,IAAI,WAAW,KAAK,CAAC,EAAE,CAAC;YACtB,iCAAiC;YACjC,MAAM,IAAI,GAAU,CAAC,SAAS,EAAE,QAAQ,EAAE,MAAM,CAAC,CAAC;YAClD,MAAM,SAAS,GAAG,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,MAAM,EAAE,GAAG,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC;YAChE,OAAO;gBACL,cAAc,EAAE,SAAS;gBACzB,UAAU,EAAE,IAAI;gBAChB,cAAc,EAAE,GAAG;gBACnB,iBAAiB,EAAE,IAAI;gBACvB,SAAS,EAAE,kDAAkD;aAC9D,CAAC;QACJ,CAAC;QAED,IAAI,OAAO,GAAQ,SAAS,CAAC;QAC7B,IAAI,OAAO,GAAG,CAAC,CAAC,CAAC;QACjB,MAAM,QAAQ,GAA0B,EAAS,CAAC;QAElD,6BAA6B;QAC5B,MAAM,CAAC,IAAI,CAAC,KAAK,CAAW,CAAC,OAAO,CAAC,CAAC,GAAG,EAAE,EAAE;YAC5C,MAAM,QAAQ,GAAG,KAAK,CAAC,GAAG,CAAC,CAAC;YAE5B,IAAI,QAAQ,CAAC,MAAM,KAAK,CAAC,EAAE,CAAC;gBAC1B,iCAAiC;gBACjC,QAAQ,CAAC,GAAG,CAAC,GAAG;oBACd,GAAG,QAAQ;oBACX,QAAQ,EAAE,QAAQ;oBAClB,gBAAgB,EAAE,QAAQ;iBAC3B,CAAC;gBACF,OAAO,GAAG,GAAG,CAAC;gBACd,OAAO,GAAG,QAAQ,CAAC;gBACnB,OAAO;YACT,CAAC;YAED,wCAAwC;YACxC,MAAM,IAAI,GAAG,QAAQ,CAAC,OAAO,CAAC;YAC9B,MAAM,gBAAgB,GACpB,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,WAAW,CAAC,CAAC,GAAG,QAAQ,CAAC,MAAM,CAAC;gBACxD,IAAI,CAAC,MAAM,CAAC,eAAe,CAAC;YAE9B,MAAM,QAAQ,GAAG,IAAI,GAAG,gBAAgB,CAAC;YAEzC,QAAQ,CAAC,GAAG,CAAC,GAAG;gBACd,GAAG,QAAQ;gBACX,QAAQ;gBACR,gBAAgB;aACjB,CAAC;YAEF,IAAI,QAAQ,GAAG,OAAO,EAAE,CAAC;gBACvB,OAAO,GAAG,QAAQ,CAAC;gBACnB,OAAO,GAAG,GAAG,CAAC;YAChB,CAAC;QACH,CAAC,CAAC,CAAC;QAEH,MAAM,SAAS,GAAG,QAAQ,CAAC,OAAO,CAAC,CAAC;QACpC,MAAM,UAAU,GACd,SAAS,CAAC,MAAM,IAAI,IAAI,CAAC,MAAM,CAAC,sBAAsB;YACpD,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,IAAI,EAAE,SAAS,CAAC,OAAO,GAAG,GAAG,CAAC;YACzC,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,GAAG,EAAE,SAAS,CAAC,OAAO,CAAC,CAAC;QAEvC,MAAM,iBAAiB,GACrB,SAAS,CAAC,gBAAgB,GAAG,GAAG;YAChC,SAAS,CAAC,MAAM,GAAG,IAAI,CAAC,MAAM,CAAC,sBAAsB,CAAC;QAExD,OAAO;YACL,cAAc,EAAE,OAAO;YACvB,UAAU;YACV,cAAc,EAAE,SAAS,CAAC,OAAO;YACjC,iBAAiB;YACjB,SAAS,EAAE,iBAAiB;gBAC1B,CAAC,CAAC,uBACE,SAAS,CAAC,MACZ,8BAA8B,SAAS,CAAC,gBAAgB,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE;gBACvE,CAAC,CAAC,oCAAoC,OAAO,KACzC,SAAS,CAAC,MACZ,YAAY,CAAC,SAAS,CAAC,OAAO,GAAG,GAAG,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,aAAa;SAClE,CAAC;IACJ,CAAC;IAED;;OAEG;IACH,iBAAiB,CAAC,OAAuB;QACvC,MAAM,SAAS,GAAG,IAAI,CAAC,MAAM,CAAC,MAAM,CAAC,OAAO,CAAC,CAAC;QAC9C,MAAM,KAAK,GAAG,IAAI,CAAC,MAAM,CAAC,QAAQ,CAAC,OAAO,CAAC,CAAC;QAC5C,MAAM,QAAQ,GAAG,KAAK,CAAC,SAAS,CAAC,CAAC;QAElC,MAAM,UAAU,GACd,QAAQ,CAAC,MAAM,IAAI,IAAI,CAAC,MAAM,CAAC,sBAAsB;YACnD,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,IAAI,EAAE,QAAQ,CAAC,OAAO,GAAG,GAAG,CAAC;YACxC,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,GAAG,EAAE,QAAQ,CAAC,OAAO,CAAC,CAAC;QAEtC,MAAM,iBAAiB,GACrB,QAAQ,CAAC,MAAM,GAAG,IAAI,CAAC,MAAM,CAAC,sBAAsB,CAAC;QAEvD,OAAO;YACL,cAAc,EAAE,SAAS;YACzB,UAAU;YACV,cAAc,EAAE,QAAQ,CAAC,OAAO;YAChC,iBAAiB;YACjB,SAAS,EAAE,8BAA8B,SAAS,kBAChD,CAAC,GAAG,QAAQ,CAAC,IACf,KAAK,CAAC,GAAG,QAAQ,CAAC,MAAM,GAAG,QAAQ,CAAC,IAAI,gBAAgB;SACzD,CAAC;IACJ,CAAC;IAED;;OAEG;IACH,eAAe,CAAC,OAAuB;QACrC,MAAM,KAAK,GAAG,IAAI,CAAC,MAAM,CAAC,QAAQ,CAAC,OAAO,CAAC,CAAC;QAC5C,MAAM,WAAW,GAAG,MAAM,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC,MAAM,CAC7C,CAAC,GAAG,EAAE,IAAI,EAAE,EAAE,CAAC,GAAG,GAAG,IAAI,CAAC,MAAM,EAChC,CAAC,CACF,CAAC;QAEF,gCAAgC;QAChC,IAAI,WAAW,GAAG,IAAI,CAAC,MAAM,CAAC,sBAAsB,GAAG,CAAC,EAAE,CAAC;YACzD,OAAO,IAAI,CAAC,YAAY,CAAC,OAAO,CAAC,CAAC;QACpC,CAAC;QAED,yCAAyC;QACzC,OAAO,IAAI,CAAC,iBAAiB,CAAC,OAAO,CAAC,CAAC;IACzC,CAAC;IAED;;OAEG;IACH,KAAK,CAAC,aAAa,CAAC,OAA0B;QAC5C,sEAAsE;QACtE,IAAI,IAAI,CAAC,iBAAiB,EAAE,CAAC;YAC3B,IAAI,CAAC;gBACH,MAAM,gBAAgB,GACpB,MAAM,IAAI,CAAC,iBAAiB,CAAC,kBAAkB,CAAC,OAAO,CAAC,CAAC;gBAE3D,IAAI,gBAAgB,CAAC,MAAM,KAAK,YAAY,EAAE,CAAC;oBAC7C,OAAO;wBACL,cAAc,EAAE,gBAAgB,CAAC,QAAQ;wBACzC,UAAU,EAAE,gBAAgB,CAAC,UAAU;wBACvC,cAAc,EAAE,GAAG,EAAE,uCAAuC;wBAC5D,iBAAiB,EAAE,KAAK;wBACxB,SAAS,EAAE,0BAA0B,gBAAgB,CAAC,cAAc,EAAE;qBACvE,CAAC;gBACJ,CAAC;YACH,CAAC;YAAC,OAAO,KAAK,EAAE,CAAC;gBACf,OAAO,CAAC,IAAI,CACV,8DAA8D,EAC9D,KAAK,CACN,CAAC;YACJ,CAAC;QACH,CAAC;QAED,mCAAmC;QACnC,OAAO,IAAI,CAAC,eAAe,CAAC,OAAO,CAAC,CAAC;IACvC,CAAC;IAED;;OAEG;IACH,KAAK,CAAC,aAAa,CACjB,OAA0B,EAC1B,GAAQ,EACR,OAAgB,EAChB,SAAiB,EACjB,QAAgB,EAChB,YAAqB;QAErB,mBAAmB;QACnB,IAAI,CAAC,MAAM,CAAC,MAAM,CAAC,GAAG,EAAE,OAAO,EAAE,QAAQ,EAAE,SAAS,EAAE,OAAO,CAAC,CAAC;QAE/D,4CAA4C;QAC5C,IAAI,IAAI,CAAC,iBAAiB,EAAE,CAAC;YAC3B,IAAI,CAAC;gBACH,MAAM,IAAI,CAAC,iBAAiB,CAAC,uBAAuB,CAAC,OAAO,EAAE,GAAG,EAAE;oBACjE,OAAO;oBACP,SAAS;oBACT,QAAQ;oBACR,YAAY;iBACb,CAAC,CAAC;YACL,CAAC;YAAC,OAAO,KAAK,EAAE,CAAC;gBACf,OAAO,CAAC,IAAI,CAAC,sCAAsC,EAAE,KAAK,CAAC,CAAC;gBAC5D,0DAA0D;YAC5D,CAAC;QACH,CAAC;QAED,8BAA8B;QAC9B,MAAM,gBAAgB,GACpB,IAAI,CAAC,mBAAmB,CAAC,IAAI,CAAC,mBAAmB,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;QAChE,IAAI,gBAAgB,IAAI,CAAC,gBAAgB,CAAC,aAAa,EAAE,CAAC;YACxD,gBAAgB,CAAC,aAAa,GAAG,OAAO,CAAC;QAC3C,CAAC;IACH,CAAC;IAED;;OAEG;IACH,4BAA4B;QAC1B,MAAM,QAAQ,GAAG,IAAI,CAAC,iBAAiB,EAAE,CAAC;QAE1C,OAAO,QAAQ,CAAC,GAAG,CAAC,CAAC,UAAU,EAAE,EAAE;YACjC,MAAM,OAAO,GAAG,IAAI,CAAC,eAAe,CAAC,UAAU,CAAC,CAAC;YACjD,MAAM,KAAK,GAAG,IAAI,CAAC,MAAM,CAAC,QAAQ,CAAC,OAAO,CAAC,CAAC;YAE5C,MAAM,cAAc,GAAqB,EAAS,CAAC;YACnD,IAAI,OAAO,GAAQ,SAAS,CAAC;YAC7B,IAAI,SAAS,GAAG,CAAC,CAAC,CAAC;YAElB,MAAM,CAAC,IAAI,CAAC,KAAK,CAAW,CAAC,OAAO,CAAC,CAAC,GAAG,EAAE,EAAE;gBAC5C,MAAM,QAAQ,GAAG,KAAK,CAAC,GAAG,CAAC,CAAC;gBAC5B,MAAM,UAAU,GACd,QAAQ,CAAC,MAAM,IAAI,IAAI,CAAC,MAAM,CAAC,sBAAsB;oBACnD,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,IAAI,EAAE,QAAQ,CAAC,OAAO,GAAG,GAAG,CAAC;oBACxC,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,GAAG,EAAE,QAAQ,CAAC,OAAO,CAAC,CAAC;gBAEtC,+DAA+D;gBAC/D,MAAM,KAAK,GACT,QAAQ,CAAC,OAAO,GAAG,GAAG;oBACtB,CAAC,CAAC,GAAG,CAAC,QAAQ,CAAC,UAAU,GAAG,CAAC,CAAC,CAAC,GAAG,GAAG;oBACrC,CAAC,CAAC,GAAG,CAAC,QAAQ,CAAC,OAAO,GAAG,IAAI,CAAC,CAAC,GAAG,GAAG,CAAC;gBAExC,cAAc,CAAC,GAAG,CAAC,GAAG;oBACpB,OAAO,EAAE,QAAQ,CAAC,OAAO;oBACzB,UAAU,EAAE,QAAQ,CAAC,UAAU;oBAC/B,OAAO,EAAE,QAAQ,CAAC,OAAO;oBACzB,MAAM,EAAE,QAAQ,CAAC,MAAM;oBACvB,UAAU;iBACX,CAAC;gBAEF,IAAI,KAAK,GAAG,SAAS,EAAE,CAAC;oBACtB,SAAS,GAAG,KAAK,CAAC;oBAClB,OAAO,GAAG,GAAG,CAAC;gBAChB,CAAC;YACH,CAAC,CAAC,CAAC;YAEH,4DAA4D;YAC5D,MAAM,WAAW,GAAG,CAAC,cAAc,CAAC,OAAO,CAAC,CAAC,OAAO,GAAG,IAAI,CAAC,GAAG,IAAI,CAAC;YAEpE,OAAO;gBACL,OAAO,EAAE,UAAU;gBACnB,cAAc;gBACd,OAAO;gBACP,WAAW;aACZ,CAAC;QACJ,CAAC,CAAC,CAAC;IACL,CAAC;IAED;;OAEG;IACH,8BAA8B;QAM5B,MAAM,eAAe,GAAG,EAAE,CAAC;QAC3B,MAAM,qBAAqB,GAAG,IAAI,CAAC,4BAA4B,EAAE,CAAC;QAClE,MAAM,WAAW,GAAG,IAAI,CAAC,MAAM,CAAC,QAAQ,EAAE,CAAC;QAE3C,gCAAgC;QAChC,MAAM,iBAAiB,GAAI,MAAM,CAAC,IAAI,CAAC,WAAW,CAAW,CAAC,MAAM,CAClE,CAAC,GAAG,EAAE,EAAE,CAAC,WAAW,CAAC,GAAG,CAAC,CAAC,MAAM,GAAG,IAAI,CAAC,MAAM,CAAC,sBAAsB,CACtE,CAAC;QAEF,IAAI,iBAAiB,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC;YACjC,eAAe,CAAC,IAAI,CAAC;gBACnB,IAAI,EAAE,aAAsB;gBAC5B,QAAQ,EAAE,MAAe;gBACzB,WAAW,EAAE,QAAQ,iBAAiB,CAAC,IAAI,CACzC,IAAI,CACL,wBAAwB;gBACzB,MAAM,EAAE,qDAAqD,iBAAiB,CAAC,IAAI,CACjF,IAAI,CACL,EAAE;aACJ,CAAC,CAAC;QACL,CAAC;QAED,2CAA2C;QAC3C,MAAM,sBAAsB,GAAG,qBAAqB,CAAC,MAAM,CACzD,CAAC,GAAG,EAAE,EAAE,CAAC,GAAG,CAAC,WAAW,GAAG,GAAG,CAAC,wCAAwC;SACxE,CAAC;QAEF,IAAI,sBAAsB,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC;YACtC,eAAe,CAAC,IAAI,CAAC;gBACnB,IAAI,EAAE,kBAA2B;gBACjC,QAAQ,EAAE,QAAiB;gBAC3B,WAAW,EAAE,iCAAiC,sBAAsB;qBACjE,GAAG,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,OAAO,CAAC;qBACrB,IAAI,CAAC,IAAI,CAAC,EAAE;gBACf,MAAM,EAAE,+DAA+D;aACxE,CAAC,CAAC;QACL,CAAC;QAED,oCAAoC;QACpC,MAAM,sBAAsB,GAAG,qBAAqB,CAAC,MAAM,CACzD,CAAC,GAAG,EAAE,EAAE,CACN,GAAG,CAAC,cAAc,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,UAAU,GAAG,GAAG;YAChD,GAAG,CAAC,cAAc,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,MAAM,GAAG,EAAE,CAC9C,CAAC;QAEF,IAAI,sBAAsB,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC;YACtC,eAAe,CAAC,IAAI,CAAC;gBACnB,IAAI,EAAE,cAAuB;gBAC7B,QAAQ,EAAE,KAAc;gBACxB,WAAW,EAAE,oCAAoC,sBAAsB,CAAC,MAAM,WAAW;gBACzF,MAAM,EAAE,uDAAuD;aAChE,CAAC,CAAC;QACL,CAAC;QAED,6CAA6C;QAC7C,MAAM,iBAAiB,GAAG,qBAAqB,CAAC,MAAM,CACpD,CAAC,GAAG,EAAE,EAAE,CACN,GAAG,CAAC,WAAW,GAAG,GAAG,IAAI,GAAG,CAAC,cAAc,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,MAAM,GAAG,EAAE,CACvE,CAAC;QAEF,IAAI,iBAAiB,CAAC,MAAM,GAAG,CAAC,IAAI,IAAI,CAAC,iBAAiB,EAAE,CAAC;YAC3D,eAAe,CAAC,IAAI,CAAC;gBACnB,IAAI,EAAE,YAAqB;gBAC3B,QAAQ,EAAE,QAAiB;gBAC3B,WAAW,EAAE,6BAA6B,iBAAiB;qBACxD,GAAG,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,OAAO,CAAC;qBACrB,IAAI,CAAC,IAAI,CAAC,EAAE;gBACf,MAAM,EAAE,8DAA8D;aACvE,CAAC,CAAC;QACL,CAAC;QAED,OAAO,eAAe,CAAC;IACzB,CAAC;IAED;;OAEG;IACK,qBAAqB;QAC3B,WAAW,CAAC,GAAG,EAAE;YACf,IAAI,CAAC,oBAAoB,EAAE,CAAC;QAC9B,CAAC,EAAE,IAAI,CAAC,MAAM,CAAC,oBAAoB,GAAG,EAAE,GAAG,IAAI,CAAC,CAAC,CAAC,wBAAwB;IAC5E,CAAC;IAED;;OAEG;IACK,KAAK,CAAC,oBAAoB;QAChC,IAAI,CAAC;YACH,MAAM,eAAe,GAAG,IAAI,CAAC,8BAA8B,EAAE,CAAC;YAE9D,sBAAsB;YACtB,IAAI,eAAe,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC;gBAC/B,OAAO,CAAC,GAAG,CAAC,sCAAsC,EAAE,eAAe,CAAC,CAAC;YACvE,CAAC;YAED,oCAAoC;YACpC,MAAM,gBAAgB,GAAG,eAAe,CAAC,MAAM,CAC7C,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,QAAQ,KAAK,MAAM,CAC7B,CAAC;YAEF,KAAK,MAAM,GAAG,IAAI,gBAAgB,EAAE,CAAC;gBACnC,IAAI,GAAG,CAAC,IAAI,KAAK,aAAa,EAAE,CAAC;oBAC/B,wCAAwC;oBACxC,IAAI,CAAC,MAAM,CAAC,eAAe,GAAG,IAAI,CAAC,GAAG,CACpC,GAAG,EACH,IAAI,CAAC,MAAM,CAAC,eAAe,GAAG,GAAG,CAClC,CAAC;oBACF,OAAO,CAAC,GAAG,CACT,oDAAoD,IAAI,CAAC,MAAM,CAAC,eAAe,EAAE,CAClF,CAAC;gBACJ,CAAC;YACH,CAAC;YAED,yCAAyC;YACzC,UAAU,CAAC,GAAG,EAAE;gBACd,IAAI,CAAC,MAAM,CAAC,eAAe,GAAG,IAAI,CAAC,GAAG,CACpC,IAAI,EACJ,IAAI,CAAC,MAAM,CAAC,eAAe,GAAG,GAAG,CAClC,CAAC;YACJ,CAAC,EAAE,EAAE,GAAG,EAAE,GAAG,IAAI,CAAC,CAAC,CAAC,aAAa;QACnC,CAAC;QAAC,OAAO,KAAK,EAAE,CAAC;YACf,OAAO,CAAC,KAAK,CAAC,8BAA8B,EAAE,KAAK,CAAC,CAAC;QACvD,CAAC;IACH,CAAC;IAED;;OAEG;IACK,iBAAiB;QACvB,qEAAqE;QACrE,uCAAuC;QACvC,OAAO;YACL,2BAA2B;YAC3B,qBAAqB;YACrB,4BAA4B;YAC5B,uBAAuB;SACxB,CAAC;IACJ,CAAC;IAED;;OAEG;IACK,eAAe,CAAC,UAAkB;QACxC,MAAM,CAAC,MAAM,EAAE,UAAU,EAAE,KAAK,CAAC,GAAG,UAAU,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC;QAC1D,OAAO;YACL,MAAM,EAAE,MAAM,KAAK,SAAS,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,CAAC,MAAM;YACjD,UAAU,EAAE,UAAU,KAAK,UAAU,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,CAAC,UAAU;YAC9D,YAAY,EAAE,KAAK,KAAK,OAAO;SAChC,CAAC;IACJ,CAAC;IAED;;OAEG;IACH,SAAS;QACP,OAAO,EAAE,GAAG,IAAI,CAAC,MAAM,EAAE,CAAC;IAC5B,CAAC;IAED;;OAEG;IACH,YAAY,CAAC,OAAoC;QAC/C,IAAI,CAAC,MAAM,GAAG,EAAE,GAAG,IAAI,CAAC,MAAM,EAAE,GAAG,OAAO,EAAE,CAAC;IAC/C,CAAC;IAED;;OAEG;IACH,sBAAsB;QACpB,OAAO,CAAC,GAAG,IAAI,CAAC,mBAAmB,CAAC,CAAC;IACvC,CAAC;IAED;;OAEG;IACH,KAAK;QACH,IAAI,CAAC,MAAM,GAAG,IAAI,kCAAc,EAAE,CAAC;QACnC,IAAI,CAAC,mBAAmB,GAAG,EAAE,CAAC;IAChC,CAAC;IAED;;OAEG;IACH,WAAW;QAKT,OAAO;YACL,WAAW,EAAE,IAAI,CAAC,MAAM,CAAC,QAAQ,EAAE;YACnC,MAAM,EAAE,IAAI,CAAC,MAAM;YACnB,mBAAmB,EAAE,IAAI,CAAC,mBAAmB;SAC9C,CAAC;IACJ,CAAC;IAED;;OAEG;IACH,cAAc;QACZ,OAAO,IAAI,CAAC,MAAM,CAAC,QAAQ,EAAE,CAAC;IAChC,CAAC;IAED;;OAEG;IACH,WAAW;QAQT,MAAM,WAAW,GAAG,IAAI,CAAC,MAAM,CAAC,QAAQ,EAAE,CAAC;QAC3C,MAAM,WAAW,GAAG,MAAM,CAAC,MAAM,CAAC,WAAW,CAAC,CAAC,MAAM,CACnD,CAAC,GAAG,EAAE,IAAI,EAAE,EAAE,CAAC,GAAG,GAAG,IAAI,CAAC,MAAM,EAChC,CAAC,CACF,CAAC;QACF,MAAM,eAAe,GAAG,IAAI,CAAC,8BAA8B,EAAE,CAAC;QAE9D,IAAI,MAAM,GAAoC,SAAS,CAAC;QAExD,IAAI,WAAW,GAAG,EAAE,EAAE,CAAC;YACrB,MAAM,GAAG,SAAS,CAAC,CAAC,kBAAkB;QACxC,CAAC;QAED,MAAM,kBAAkB,GAAG,eAAe,CAAC,MAAM,CAC/C,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,QAAQ,KAAK,MAAM,CAC7B,CAAC;QACF,IAAI,kBAAkB,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC;YAClC,MAAM,GAAG,SAAS,CAAC;QACrB,CAAC;QAED,OAAO;YACL,MAAM;YACN,WAAW;YACX,cAAc,EAAE,IAAI,CAAC,iBAAiB,EAAE,CAAC,MAAM;YAC/C,uBAAuB,EAAE,IAAI,CAAC,MAAM,CAAC,uBAAuB;YAC5D,gBAAgB,EACd,IAAI,CAAC,mBAAmB,CAAC,IAAI,CAAC,mBAAmB,CAAC,MAAM,GAAG,CAAC,CAAC;gBAC3D,EAAE,SAAS;YACf,eAAe,EAAE,eAAe,CAAC,MAAM;SACxC,CAAC;IACJ,CAAC;CACF;AA5hBD,0CA4hBC;AAED,4CAA4C;AAC/B,QAAA,WAAW,GAAG;IACzB;;OAEG;IACH,qBAAqB,CACnB,IAAsC,EACtC,IAAsC;QAMtC,IAAI,IAAI,CAAC,MAAM,KAAK,CAAC,IAAI,IAAI,CAAC,MAAM,KAAK,CAAC,EAAE,CAAC;YAC3C,OAAO,EAAE,WAAW,EAAE,KAAK,EAAE,MAAM,EAAE,CAAC,EAAE,kBAAkB,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC;QACvE,CAAC;QAED,MAAM,EAAE,GAAG,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,MAAM,CAAC;QACnC,MAAM,EAAE,GAAG,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,MAAM,CAAC;QACnC,MAAM,IAAI,GAAG,EAAE,GAAG,EAAE,CAAC;QAErB,8BAA8B;QAC9B,MAAM,EAAE,GAAG,IAAI,CAAC,IAAI,CAClB,CAAC,EAAE,GAAG,CAAC,CAAC,GAAG,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,MAAM,GAAG,CAAC,EAAE,GAAG,CAAC,CAAC,GAAG,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,MAAM,CAC9D,CAAC;QAEF,MAAM,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,GAAG,EAAE,CAAC;QAC9B,MAAM,MAAM,GAAG,CAAC,GAAG,CAAC,CAAC,GAAG,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,kBAAkB;QAE9D,MAAM,MAAM,GAAG,IAAI,GAAG,EAAE,CAAC,CAAC,0BAA0B;QACpD,MAAM,kBAAkB,GAAqB,CAAC,IAAI,GAAG,MAAM,EAAE,IAAI,GAAG,MAAM,CAAC,CAAC;QAE5E,OAAO;YACL,WAAW,EAAE,MAAM,GAAG,IAAI;YAC1B,MAAM;YACN,kBAAkB;SACnB,CAAC;IACJ,CAAC;IAED;;OAEG;IACH,SAAS,CAAC,CAAS;QACjB,OAAO,GAAG,GAAG,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;IAChD,CAAC;IAED;;OAEG;IACH,GAAG,CAAC,CAAS;QACX,sCAAsC;QACtC,MAAM,EAAE,GAAG,WAAW,CAAC;QACvB,MAAM,EAAE,GAAG,CAAC,WAAW,CAAC;QACxB,MAAM,EAAE,GAAG,WAAW,CAAC;QACvB,MAAM,EAAE,GAAG,CAAC,WAAW,CAAC;QACxB,MAAM,EAAE,GAAG,WAAW,CAAC;QACvB,MAAM,CAAC,GAAG,SAAS,CAAC;QAEpB,MAAM,IAAI,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAC7B,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;QAEhB,MAAM,CAAC,GAAG,GAAG,GAAG,CAAC,GAAG,GAAG,CAAC,GAAG,CAAC,CAAC,CAAC;QAC9B,MAAM,CAAC,GACL,GAAG;YACH,CAAC,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;QAExE,OAAO,IAAI,GAAG,CAAC,CAAC;IAClB,CAAC;IAED;;OAEG;IACH,eAAe,CACb,WAAgC,EAChC,UAA+C;QAE/C,MAAM,aAAa,GAAG,IAAI,CAAC,GAAG,CAAC,GAAG,MAAM,CAAC,MAAM,CAAC,WAAW,CAAC,CAAC,CAAC;QAC9D,IAAI,WAAW,GAAG,CAAC,CAAC;QAEpB,UAAU,CAAC,OAAO,CAAC,CAAC,SAAS,EAAE,EAAE;YAC/B,MAAM,MAAM,GAAG,aAAa,GAAG,WAAW,CAAC,SAAS,CAAC,GAAG,CAAC,CAAC;YAC1D,WAAW,IAAI,MAAM,CAAC;QACxB,CAAC,CAAC,CAAC;QAEH,OAAO,WAAW,GAAG,UAAU,CAAC,MAAM,CAAC,CAAC,iBAAiB;IAC3D,CAAC;CACF,CAAC","names":[],"sources":["/Users/matbakh-visibility-boost.20250920/src/lib/ai-orchestrator/bandit-optimizer.ts"],"sourcesContent":["/**\n * Bandit Optimizer for AI Model Selection\n *\n * Implements:\n * - UCB (Upper Confidence Bound) algorithm\n * - Thompson Sampling with Beta distribution\n * - Contextual bandits for persona-based routing\n * - Integration with Evidently experiments\n * - Automated optimization and learning\n */\n\nimport {\n  Arm,\n  ArmStats,\n  BanditContext,\n  ThompsonBandit,\n} from \"./bandit-controller\";\nimport {\n  EvidentlyExperimentManager,\n  ExperimentContext,\n} from \"./evidently-experiments\";\n\nexport interface UCBStats extends ArmStats {\n  ucbScore: number;\n  confidenceRadius: number;\n}\n\nexport interface OptimizationConfig {\n  explorationRate: number; // 0-1, higher = more exploration\n  confidenceLevel: number; // 0-1, for UCB confidence intervals\n  minTrialsForConfidence: number; // Minimum trials before trusting results\n  autoOptimizationEnabled: boolean;\n  optimizationInterval: number; // Minutes between optimization runs\n}\n\nexport interface OptimizationResult {\n  recommendedArm: Arm;\n  confidence: number;\n  expectedReward: number;\n  explorationNeeded: boolean;\n  reasoning: string;\n}\n\nexport interface ContextualPerformance {\n  context: string;\n  armPerformance: Record<\n    Arm,\n    {\n      winRate: number;\n      avgLatency: number;\n      avgCost: number;\n      trials: number;\n      confidence: number;\n    }\n  >;\n  bestArm: Arm;\n  improvement: number;\n}\n\nexport class BanditOptimizer {\n  private bandit: ThompsonBandit;\n  private experimentManager?: EvidentlyExperimentManager;\n  private config: OptimizationConfig;\n  private optimizationHistory: Array<{\n    timestamp: Date;\n    context?: BanditContext;\n    result: OptimizationResult;\n    actualOutcome?: boolean;\n  }> = [];\n\n  constructor(\n    bandit?: ThompsonBandit,\n    experimentManager?: EvidentlyExperimentManager,\n    config?: Partial<OptimizationConfig>\n  ) {\n    this.bandit = bandit || new ThompsonBandit();\n    this.experimentManager = experimentManager;\n    this.config = {\n      explorationRate: 0.1,\n      confidenceLevel: 0.95,\n      minTrialsForConfidence: 20,\n      autoOptimizationEnabled: true,\n      optimizationInterval: 60, // 1 hour\n      ...config,\n    };\n\n    if (this.config.autoOptimizationEnabled) {\n      this.startAutoOptimization();\n    }\n  }\n\n  /**\n   * UCB (Upper Confidence Bound) algorithm for arm selection\n   */\n  selectArmUCB(context?: BanditContext): OptimizationResult {\n    const stats = this.bandit.getStats(context);\n    const totalTrials = Object.values(stats).reduce(\n      (sum, stat) => sum + stat.trials,\n      0\n    );\n\n    if (totalTrials === 0) {\n      // No data yet, return random arm\n      const arms: Arm[] = [\"bedrock\", \"google\", \"meta\"];\n      const randomArm = arms[Math.floor(Math.random() * arms.length)];\n      return {\n        recommendedArm: randomArm,\n        confidence: 0.33,\n        expectedReward: 0.5,\n        explorationNeeded: true,\n        reasoning: \"No historical data available, exploring randomly\",\n      };\n    }\n\n    let bestArm: Arm = \"bedrock\";\n    let bestUCB = -1;\n    const ucbStats: Record<Arm, UCBStats> = {} as any;\n\n    // Calculate UCB for each arm\n    (Object.keys(stats) as Arm[]).forEach((arm) => {\n      const armStats = stats[arm];\n\n      if (armStats.trials === 0) {\n        // Unplayed arm gets infinite UCB\n        ucbStats[arm] = {\n          ...armStats,\n          ucbScore: Infinity,\n          confidenceRadius: Infinity,\n        };\n        bestArm = arm;\n        bestUCB = Infinity;\n        return;\n      }\n\n      // UCB formula: mean + confidence_radius\n      const mean = armStats.winRate;\n      const confidenceRadius =\n        Math.sqrt((2 * Math.log(totalTrials)) / armStats.trials) *\n        this.config.explorationRate;\n\n      const ucbScore = mean + confidenceRadius;\n\n      ucbStats[arm] = {\n        ...armStats,\n        ucbScore,\n        confidenceRadius,\n      };\n\n      if (ucbScore > bestUCB) {\n        bestUCB = ucbScore;\n        bestArm = arm;\n      }\n    });\n\n    const bestStats = ucbStats[bestArm];\n    const confidence =\n      bestStats.trials >= this.config.minTrialsForConfidence\n        ? Math.min(0.95, bestStats.winRate + 0.1)\n        : Math.max(0.3, bestStats.winRate);\n\n    const explorationNeeded =\n      bestStats.confidenceRadius > 0.1 ||\n      bestStats.trials < this.config.minTrialsForConfidence;\n\n    return {\n      recommendedArm: bestArm,\n      confidence,\n      expectedReward: bestStats.winRate,\n      explorationNeeded,\n      reasoning: explorationNeeded\n        ? `Exploration needed: ${\n            bestStats.trials\n          } trials, confidence radius ${bestStats.confidenceRadius.toFixed(3)}`\n        : `Exploitation: High confidence in ${bestArm} (${\n            bestStats.trials\n          } trials, ${(bestStats.winRate * 100).toFixed(1)}% win rate)`,\n    };\n  }\n\n  /**\n   * Thompson Sampling with contextual information\n   */\n  selectArmThompson(context?: BanditContext): OptimizationResult {\n    const chosenArm = this.bandit.choose(context);\n    const stats = this.bandit.getStats(context);\n    const armStats = stats[chosenArm];\n\n    const confidence =\n      armStats.trials >= this.config.minTrialsForConfidence\n        ? Math.min(0.95, armStats.winRate + 0.1)\n        : Math.max(0.3, armStats.winRate);\n\n    const explorationNeeded =\n      armStats.trials < this.config.minTrialsForConfidence;\n\n    return {\n      recommendedArm: chosenArm,\n      confidence,\n      expectedReward: armStats.winRate,\n      explorationNeeded,\n      reasoning: `Thompson Sampling selected ${chosenArm} based on Beta(${\n        1 + armStats.wins\n      }, ${1 + armStats.trials - armStats.wins}) distribution`,\n    };\n  }\n\n  /**\n   * Hybrid approach: UCB for exploration, Thompson for exploitation\n   */\n  selectArmHybrid(context?: BanditContext): OptimizationResult {\n    const stats = this.bandit.getStats(context);\n    const totalTrials = Object.values(stats).reduce(\n      (sum, stat) => sum + stat.trials,\n      0\n    );\n\n    // Use UCB for early exploration\n    if (totalTrials < this.config.minTrialsForConfidence * 3) {\n      return this.selectArmUCB(context);\n    }\n\n    // Use Thompson Sampling for exploitation\n    return this.selectArmThompson(context);\n  }\n\n  /**\n   * Get optimal arm with experiment integration\n   */\n  async getOptimalArm(context: ExperimentContext): Promise<OptimizationResult> {\n    // Check if experiment manager is available and has active experiments\n    if (this.experimentManager) {\n      try {\n        const experimentResult =\n          await this.experimentManager.getOptimalProvider(context);\n\n        if (experimentResult.source === \"experiment\") {\n          return {\n            recommendedArm: experimentResult.provider,\n            confidence: experimentResult.confidence,\n            expectedReward: 0.8, // Assume experiments are well-designed\n            explorationNeeded: false,\n            reasoning: `Experiment assignment: ${experimentResult.experimentName}`,\n          };\n        }\n      } catch (error) {\n        console.warn(\n          \"Failed to get experiment assignment, falling back to bandit:\",\n          error\n        );\n      }\n    }\n\n    // Fall back to bandit optimization\n    return this.selectArmHybrid(context);\n  }\n\n  /**\n   * Record outcome and update optimization\n   */\n  async recordOutcome(\n    context: ExperimentContext,\n    arm: Arm,\n    success: boolean,\n    latencyMs: number,\n    costEuro: number,\n    qualityScore?: number\n  ): Promise<void> {\n    // Record in bandit\n    this.bandit.record(arm, success, costEuro, latencyMs, context);\n\n    // Record in experiment manager if available\n    if (this.experimentManager) {\n      try {\n        await this.experimentManager.recordExperimentOutcome(context, arm, {\n          success,\n          latencyMs,\n          costEuro,\n          qualityScore,\n        });\n      } catch (error) {\n        console.warn(\"Failed to record experiment outcome:\", error);\n        // Continue execution - bandit recording is more important\n      }\n    }\n\n    // Update optimization history\n    const lastOptimization =\n      this.optimizationHistory[this.optimizationHistory.length - 1];\n    if (lastOptimization && !lastOptimization.actualOutcome) {\n      lastOptimization.actualOutcome = success;\n    }\n  }\n\n  /**\n   * Analyze contextual performance across different contexts\n   */\n  analyzeContextualPerformance(): ContextualPerformance[] {\n    const contexts = this.getUniqueContexts();\n\n    return contexts.map((contextKey) => {\n      const context = this.parseContextKey(contextKey);\n      const stats = this.bandit.getStats(context);\n\n      const armPerformance: Record<Arm, any> = {} as any;\n      let bestArm: Arm = \"bedrock\";\n      let bestScore = -1;\n\n      (Object.keys(stats) as Arm[]).forEach((arm) => {\n        const armStats = stats[arm];\n        const confidence =\n          armStats.trials >= this.config.minTrialsForConfidence\n            ? Math.min(0.95, armStats.winRate + 0.1)\n            : Math.max(0.3, armStats.winRate);\n\n        // Composite score: win rate (50%) + latency (30%) + cost (20%)\n        const score =\n          armStats.winRate * 0.5 +\n          (1 / (armStats.avgLatency + 1)) * 0.3 +\n          (1 / (armStats.avgCost + 0.01)) * 0.2;\n\n        armPerformance[arm] = {\n          winRate: armStats.winRate,\n          avgLatency: armStats.avgLatency,\n          avgCost: armStats.avgCost,\n          trials: armStats.trials,\n          confidence,\n        };\n\n        if (score > bestScore) {\n          bestScore = score;\n          bestArm = arm;\n        }\n      });\n\n      // Calculate improvement over random baseline (33% win rate)\n      const improvement = (armPerformance[bestArm].winRate - 0.33) / 0.33;\n\n      return {\n        context: contextKey,\n        armPerformance,\n        bestArm,\n        improvement,\n      };\n    });\n  }\n\n  /**\n   * Get optimization recommendations based on current performance\n   */\n  getOptimizationRecommendations(): Array<{\n    type: \"exploration\" | \"exploitation\" | \"context_specific\" | \"experiment\";\n    priority: \"high\" | \"medium\" | \"low\";\n    description: string;\n    action: string;\n  }> {\n    const recommendations = [];\n    const contextualPerformance = this.analyzeContextualPerformance();\n    const globalStats = this.bandit.getStats();\n\n    // Check for under-explored arms\n    const underExploredArms = (Object.keys(globalStats) as Arm[]).filter(\n      (arm) => globalStats[arm].trials < this.config.minTrialsForConfidence\n    );\n\n    if (underExploredArms.length > 0) {\n      recommendations.push({\n        type: \"exploration\" as const,\n        priority: \"high\" as const,\n        description: `Arms ${underExploredArms.join(\n          \", \"\n        )} need more exploration`,\n        action: `Increase exploration rate or force exploration of ${underExploredArms.join(\n          \", \"\n        )}`,\n      });\n    }\n\n    // Check for contexts with poor performance\n    const poorPerformingContexts = contextualPerformance.filter(\n      (ctx) => ctx.improvement < 0.1 // Less than 10% improvement over random\n    );\n\n    if (poorPerformingContexts.length > 0) {\n      recommendations.push({\n        type: \"context_specific\" as const,\n        priority: \"medium\" as const,\n        description: `Poor performance in contexts: ${poorPerformingContexts\n          .map((c) => c.context)\n          .join(\", \")}`,\n        action: \"Consider context-specific optimization or feature engineering\",\n      });\n    }\n\n    // Check for high-confidence winners\n    const highConfidenceContexts = contextualPerformance.filter(\n      (ctx) =>\n        ctx.armPerformance[ctx.bestArm].confidence > 0.9 &&\n        ctx.armPerformance[ctx.bestArm].trials > 50\n    );\n\n    if (highConfidenceContexts.length > 0) {\n      recommendations.push({\n        type: \"exploitation\" as const,\n        priority: \"low\" as const,\n        description: `High confidence winners found in ${highConfidenceContexts.length} contexts`,\n        action: \"Consider reducing exploration rate for these contexts\",\n      });\n    }\n\n    // Suggest experiments for promising contexts\n    const promisingContexts = contextualPerformance.filter(\n      (ctx) =>\n        ctx.improvement > 0.2 && ctx.armPerformance[ctx.bestArm].trials > 30\n    );\n\n    if (promisingContexts.length > 0 && this.experimentManager) {\n      recommendations.push({\n        type: \"experiment\" as const,\n        priority: \"medium\" as const,\n        description: `Promising contexts found: ${promisingContexts\n          .map((c) => c.context)\n          .join(\", \")}`,\n        action: \"Consider running formal A/B experiments to validate findings\",\n      });\n    }\n\n    return recommendations;\n  }\n\n  /**\n   * Start automatic optimization process\n   */\n  private startAutoOptimization(): void {\n    setInterval(() => {\n      this.runOptimizationCycle();\n    }, this.config.optimizationInterval * 60 * 1000); // Convert minutes to ms\n  }\n\n  /**\n   * Run a single optimization cycle\n   */\n  private async runOptimizationCycle(): Promise<void> {\n    try {\n      const recommendations = this.getOptimizationRecommendations();\n\n      // Log recommendations\n      if (recommendations.length > 0) {\n        console.log(\"Bandit Optimization Recommendations:\", recommendations);\n      }\n\n      // Auto-apply low-risk optimizations\n      const highPriorityRecs = recommendations.filter(\n        (r) => r.priority === \"high\"\n      );\n\n      for (const rec of highPriorityRecs) {\n        if (rec.type === \"exploration\") {\n          // Temporarily increase exploration rate\n          this.config.explorationRate = Math.min(\n            0.3,\n            this.config.explorationRate * 1.2\n          );\n          console.log(\n            `Auto-optimization: Increased exploration rate to ${this.config.explorationRate}`\n          );\n        }\n      }\n\n      // Reset exploration rate after some time\n      setTimeout(() => {\n        this.config.explorationRate = Math.max(\n          0.05,\n          this.config.explorationRate * 0.9\n        );\n      }, 30 * 60 * 1000); // 30 minutes\n    } catch (error) {\n      console.error(\"Error in optimization cycle:\", error);\n    }\n  }\n\n  /**\n   * Get unique contexts from bandit history\n   */\n  private getUniqueContexts(): string[] {\n    // This would need to be implemented based on how contexts are stored\n    // For now, return some common contexts\n    return [\n      \"general|standard|no-tools\",\n      \"legal|premium|tools\",\n      \"culinary|standard|no-tools\",\n      \"medical|premium|tools\",\n    ];\n  }\n\n  /**\n   * Parse context key back to BanditContext\n   */\n  private parseContextKey(contextKey: string): BanditContext {\n    const [domain, budgetTier, tools] = contextKey.split(\"|\");\n    return {\n      domain: domain === \"general\" ? undefined : domain,\n      budgetTier: budgetTier === \"standard\" ? undefined : budgetTier,\n      requireTools: tools === \"tools\",\n    };\n  }\n\n  /**\n   * Get current configuration\n   */\n  getConfig(): OptimizationConfig {\n    return { ...this.config };\n  }\n\n  /**\n   * Update configuration\n   */\n  updateConfig(updates: Partial<OptimizationConfig>): void {\n    this.config = { ...this.config, ...updates };\n  }\n\n  /**\n   * Get optimization history\n   */\n  getOptimizationHistory(): typeof this.optimizationHistory {\n    return [...this.optimizationHistory];\n  }\n\n  /**\n   * Reset bandit and optimization history\n   */\n  reset(): void {\n    this.bandit = new ThompsonBandit();\n    this.optimizationHistory = [];\n  }\n\n  /**\n   * Export bandit state for persistence\n   */\n  exportState(): {\n    banditStats: ReturnType<ThompsonBandit[\"getStats\"]>;\n    config: OptimizationConfig;\n    optimizationHistory: typeof this.optimizationHistory;\n  } {\n    return {\n      banditStats: this.bandit.getStats(),\n      config: this.config,\n      optimizationHistory: this.optimizationHistory,\n    };\n  }\n\n  /**\n   * Get bandit statistics\n   */\n  getBanditStats(): ReturnType<ThompsonBandit[\"getStats\"]> {\n    return this.bandit.getStats();\n  }\n\n  /**\n   * Health check for the optimizer\n   */\n  healthCheck(): {\n    status: \"healthy\" | \"warning\" | \"error\";\n    totalTrials: number;\n    activeContexts: number;\n    autoOptimizationEnabled: boolean;\n    lastOptimization?: Date;\n    recommendations: number;\n  } {\n    const globalStats = this.bandit.getStats();\n    const totalTrials = Object.values(globalStats).reduce(\n      (sum, stat) => sum + stat.trials,\n      0\n    );\n    const recommendations = this.getOptimizationRecommendations();\n\n    let status: \"healthy\" | \"warning\" | \"error\" = \"healthy\";\n\n    if (totalTrials < 10) {\n      status = \"warning\"; // Not enough data\n    }\n\n    const highPriorityIssues = recommendations.filter(\n      (r) => r.priority === \"high\"\n    );\n    if (highPriorityIssues.length > 0) {\n      status = \"warning\";\n    }\n\n    return {\n      status,\n      totalTrials,\n      activeContexts: this.getUniqueContexts().length,\n      autoOptimizationEnabled: this.config.autoOptimizationEnabled,\n      lastOptimization:\n        this.optimizationHistory[this.optimizationHistory.length - 1]\n          ?.timestamp,\n      recommendations: recommendations.length,\n    };\n  }\n}\n\n// Utility functions for bandit optimization\nexport const BanditUtils = {\n  /**\n   * Calculate statistical significance between two arms\n   */\n  calculateSignificance(\n    arm1: { wins: number; trials: number },\n    arm2: { wins: number; trials: number }\n  ): {\n    significant: boolean;\n    pValue: number;\n    confidenceInterval: [number, number];\n  } {\n    if (arm1.trials === 0 || arm2.trials === 0) {\n      return { significant: false, pValue: 1, confidenceInterval: [0, 1] };\n    }\n\n    const p1 = arm1.wins / arm1.trials;\n    const p2 = arm2.wins / arm2.trials;\n    const diff = p1 - p2;\n\n    // Simple z-test approximation\n    const se = Math.sqrt(\n      (p1 * (1 - p1)) / arm1.trials + (p2 * (1 - p2)) / arm2.trials\n    );\n\n    const z = Math.abs(diff) / se;\n    const pValue = 2 * (1 - this.normalCDF(z)); // Two-tailed test\n\n    const margin = 1.96 * se; // 95% confidence interval\n    const confidenceInterval: [number, number] = [diff - margin, diff + margin];\n\n    return {\n      significant: pValue < 0.05,\n      pValue,\n      confidenceInterval,\n    };\n  },\n\n  /**\n   * Normal CDF approximation\n   */\n  normalCDF(x: number): number {\n    return 0.5 * (1 + this.erf(x / Math.sqrt(2)));\n  },\n\n  /**\n   * Error function approximation\n   */\n  erf(x: number): number {\n    // Abramowitz and Stegun approximation\n    const a1 = 0.254829592;\n    const a2 = -0.284496736;\n    const a3 = 1.421413741;\n    const a4 = -1.453152027;\n    const a5 = 1.061405429;\n    const p = 0.3275911;\n\n    const sign = x >= 0 ? 1 : -1;\n    x = Math.abs(x);\n\n    const t = 1.0 / (1.0 + p * x);\n    const y =\n      1.0 -\n      ((((a5 * t + a4) * t + a3) * t + a2) * t + a1) * t * Math.exp(-x * x);\n\n    return sign * y;\n  },\n\n  /**\n   * Calculate expected regret for an arm selection strategy\n   */\n  calculateRegret(\n    trueRewards: Record<Arm, number>,\n    selections: Array<{ arm: Arm; reward: number }>\n  ): number {\n    const optimalReward = Math.max(...Object.values(trueRewards));\n    let totalRegret = 0;\n\n    selections.forEach((selection) => {\n      const regret = optimalReward - trueRewards[selection.arm];\n      totalRegret += regret;\n    });\n\n    return totalRegret / selections.length; // Average regret\n  },\n};\n"],"version":3}